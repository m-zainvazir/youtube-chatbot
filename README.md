# Building Video Q&A Applications with LangChain

This project demonstrates how to build a **Video Question-Answering
(Video Q&A)** system that lets users ask natural-language questions
about a YouTube video and receive context-aware answers generated by a
Large Language Model (LLM). Acts like a **Chatbot for a Youtube video**

------------------------------------------------------------------------

## üìñ Project Overview

-   **Transcript Extraction** -- Fetch captions from a YouTube video
    using its ID.\
-   **Text Processing** -- Split the transcript into manageable chunks
    for efficient search.\
-   **Embedding & Storage** -- Convert chunks into vector embeddings and
    store them in a FAISS vector database.\
-   **Retrieval & Generation** -- Retrieve the most relevant chunks for
    a user's query and generate an answer using an LLM.

------------------------------------------------------------------------

## üõ†Ô∏è Tech Stack

 | Component                        | Package / Version                                   |
|----------------------------------|------------------------------------------------------|
| **LangChain Core**               | `langchain`, `langchain-community`, `langchain-openai` |
| **Transcript Extraction**        | `youtube-transcript-api`                             |
| **Vector Database**              | `faiss-cpu` (used in code) / `chromadb` (alternative) |
| **Embeddings**                   | `sentence-transformers` (HuggingFace)                |
| **Document Processing**          | `tiktoken`                                           |
| **Environment Management**       | `python-dotenv`                                      |
| **Web / UI (optional)**          | `streamlit`, `fastapi`                               |

------------------------------------------------------------------------

## üìÇ Project Structure

    video-qa-langchain/
    ‚îú‚îÄ main.py                 # Core script
    ‚îú‚îÄ requirements.txt        # Python dependencies
    ‚îî‚îÄ README.md

------------------------------------------------------------------------

## ‚ñ∂Ô∏è Quick Start

1.  **Clone the repository**

    ``` bash
    git clone https://github.com/<your-username>/video-qa-langchain.git
    cd video-qa-langchain
    ```

2.  **Create and activate a virtual environment**

    ``` bash
    python -m venv venv
    source venv/bin/activate     # On Windows: venv\Scripts\activate
    ```

3.  **Install dependencies**

    ``` bash
    pip install -r requirements.txt
    ```

4.  **Set environment variables** Create a `.env` file and add your keys
    (e.g., OpenAI or Groq):

        OPENAI_API_KEY=your_api_key
        GROQ_API_KEY=your_api_key

5.  **Run the application**

    ``` bash
    python main.py
    ```

    -   Enter a YouTube video ID when prompted.
    -   Ask a natural-language question about the video.

------------------------------------------------------------------------

## üí° How It Works

1.  **Fetch Transcript**: Uses `youtube-transcript-api` to pull
    captions.\
2.  **Split & Embed**: `RecursiveCharacterTextSplitter` divides text
    into 1,000-character chunks with overlap.\
3.  **Vector Store**: `FAISS` stores embeddings created with
    `HuggingFaceEmbeddings`.\
4.  **Retrieve & Answer**: A Groq-hosted `llama-3.1-8b-instant` model
    retrieves relevant chunks and generates an answer based solely on
    transcript context.

------------------------------------------------------------------------

## üß© Key Code Snippet

``` python
# Retrieval and Generation
retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 4})
question  = input("Ask Question: ")
retrieved_docs = retriever.invoke(question)
context_text = "\n\n".join(doc.page_content for doc in retrieved_docs)
final_prompt = prompt.invoke({"context": context_text, "question": question})
answer = llm.invoke(final_prompt)
print(answer.content)
```

------------------------------------------------------------------------

## ‚ú® Features

-   Converts any YouTube video (with captions) into a searchable
    knowledge base.
-   Retrieves only the most relevant transcript sections for precise,
    context-aware answers.
-   Easily extendable with Streamlit or FastAPI for a web interface.

------------------------------------------------------------------------

## üìú License

MIT License -- you are free to use and modify this project.

------------------------------------------------------------------------

### Author

Muhammad Zain Vazir
